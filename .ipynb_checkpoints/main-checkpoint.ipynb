{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import re\n",
    "from builtins import list as imp_list\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import chardet\n",
    "import pymorphy2\n",
    "\n",
    "\n",
    "def lemmatize():\n",
    "    current_dir = 'D:\\\\Programms\\\\python programms\\\\diplom_lematizer_try1' #os.path.dirname(os.path.abspath(__file__))\n",
    "    f = \"in.txt\"\n",
    "    with open(current_dir + \"\\\\\" + f, mode='rb') as file:\n",
    "        text = file.read()\n",
    "    codepage = chardet.detect(text)['encoding']\n",
    "    text = text.decode(codepage)\n",
    "    text = \" \".join(word.lower() for word in text.split())  # lowercasing and removing short words\n",
    "    text = re.sub('\\s\\r\\n\\s{1,}|\\s\\r\\n|\\r\\n', '', text)  # deleting newlines and line-breaks\n",
    "    text = re.sub('[,:;%©*@#$^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}', ' ', text)  # deleting symbols\n",
    "    text = re.sub('[.]', ' .', text)\n",
    "    text = re.sub('[!]', ' !', text)\n",
    "    text = re.sub('[?]', ' ?', text)\n",
    "    text = \" \".join(pymorphy2.MorphAnalyzer().parse(str(word))[0].normal_form for word in text.split())\n",
    "    return text\n",
    "\n",
    "@dataclass\n",
    "class VocNode:\n",
    "    key: str\n",
    "    tag: str\n",
    "    pos: imp_list\n",
    "    dist: imp_list = field(default_factory=imp_list)\n",
    "\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class Voc:\n",
    "    nodes: imp_list = field(default_factory=imp_list)\n",
    "\n",
    "    def contains_key(self, key):\n",
    "        for n in self.nodes:\n",
    "            if n.get_key() == key:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_node_by_key(self, key) -> VocNode:\n",
    "        for n in self.nodes:\n",
    "            if n.get_key() == key:\n",
    "                return n\n",
    "\n",
    "    def sort(self):\n",
    "        self.nodes.sort(key=operator.attrgetter('tag', 'key'))\n",
    "\n",
    "    def simplify(self):\n",
    "        self.nodes = [n for n in self.nodes if not n.tag == \"O\"]\n",
    "\n",
    "    def get_synsets_by_tag(self):\n",
    "        _a = []\n",
    "        _n = []\n",
    "        _v = []\n",
    "        for node in self.nodes:\n",
    "            if node.tag == 'A':\n",
    "                _a.append(node)\n",
    "            elif node.tag == 'N':\n",
    "                _n.append(node)\n",
    "            elif node.tag == 'V':\n",
    "                _v.append(node)\n",
    "        return [_a, _n, _v]\n",
    "\n",
    "\n",
    "def build_vocabulary(text):\n",
    "    voc = Voc()\n",
    "    words = text.split()\n",
    "    sent = 0\n",
    "    for i in range(len(words)):\n",
    "        if re.compile(r'[.!?]').search(words[i]):\n",
    "            sent += 1\n",
    "            continue\n",
    "        if not voc.contains_key(words[i]):\n",
    "            word = words[i]\n",
    "            p = pymorphy2.MorphAnalyzer().parse(word)[0]\n",
    "            tag = 'O'  # o - other\n",
    "            if 'NOUN' in p.tag:\n",
    "                tag = 'N'\n",
    "            elif 'INFN' in p.tag:\n",
    "                tag = 'V'\n",
    "            elif 'ADJF' in p.tag:\n",
    "                tag = 'A'\n",
    "            voc.nodes.append(VocNode(words[i], tag, [[i - sent, sent]]))\n",
    "        else:\n",
    "            node = voc.get_node_by_key(words[i])\n",
    "            node.pos.append([i - sent, sent])\n",
    "    return voc\n",
    "\n",
    "\n",
    "def print_vocabulary(_voc, _filename):\n",
    "    with open(_filename, 'w') as out:\n",
    "        for node in _voc.nodes:\n",
    "            out.write(node.key + \",\" + node.tag + \"=\" + str(node.pos) + \"&\" + str(node.dist) + \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-bff67b2b985b>:19: FutureWarning: Possible nested set at position 24\n",
      "  text = re.sub('[,:;%©*@#$^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}', ' ', text)  # deleting symbols\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize()\n",
    "voc = build_vocabulary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_vocabulary(voc, 'out.txt')\n",
    "voc.sort()\n",
    "print_vocabulary(voc, 'out_sort.txt')\n",
    "voc.simplify()\n",
    "print_vocabulary(voc, 'out_sort_simp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[a, n, v] = voc.get_synsets_by_tag()\n",
    "\n",
    "#import xml.etree.ElementTree as etree\n",
    "import lxml.etree as etree\n",
    "\n",
    "poses = ['A', 'N', 'V']\n",
    "synsets_dict = {'A' : dict(), 'N' : dict(), 'V' : dict()}\n",
    "words_dict = {'A' : dict(), 'N' : dict(), 'V' : dict()}\n",
    "for pos in poses:\n",
    "    l = []\n",
    "    if pos == 'A':\n",
    "        l = a\n",
    "    elif pos == 'N':\n",
    "        l = n\n",
    "    elif pos == 'V':\n",
    "        l = v\n",
    "    synset_str = 'rwn\\\\synsets.' + pos + '.xml'\n",
    "    sense_str = 'rwn\\\\senses.' + pos + '.xml'\n",
    "    tree = etree.parse(sense_str)\n",
    "    root = tree.getroot()\n",
    "    for node in l:\n",
    "        entries = tree.xpath(\"//sense[@name='\" + node.key.upper() + \"']\")\n",
    "        for entry in entries:\n",
    "            synset_id = entry.attrib['synset_id']\n",
    "            word = entry.attrib['name']\n",
    "            if not synset_id in synsets_dict[pos]:\n",
    "                synsets_dict[pos][synset_id] = []\n",
    "            synsets_dict[pos][synset_id].append(word)\n",
    "            if not word in words_dict[pos]:\n",
    "                words_dict[pos][word] = []\n",
    "            words_dict[pos][word].append(synset_id)\n",
    "            #print(word + '\\t' + synset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element senses at 0x133e6c8>\n",
      "Прошло времени: 51.21494793891907\n"
     ]
    }
   ],
   "source": [
    "# однокоренные ищутся по derived_from\n",
    "import time\n",
    "import collections\n",
    "\n",
    "sameroot_table = dict()\n",
    "for n in voc.nodes:\n",
    "    sameroot_table[n.key] = { i.key : 0 for i in voc.nodes }\n",
    "start = time.time()\n",
    "derived_str = 'rwn\\\\derived_from.xml'\n",
    "tree = etree.parse(derived_str)\n",
    "root = tree.getroot()\n",
    "print(root)\n",
    "for pos in poses:\n",
    "    for node1 in voc.nodes:\n",
    "        entries = tree.xpath(\"sense[@name='\" + node1.key.upper() + \"']/derived_from/*\")\n",
    "        entries = set(entries)\n",
    "        if len(entries) == 0:\n",
    "            continue\n",
    "        # entries_without_duplicates = set()\n",
    "        # remove repeated entries if id equals\n",
    "        entries_without_duplicates = collections.OrderedDict()\n",
    "        for obj in entries:\n",
    "            # eliminate this check if you want the last item\n",
    "            if obj.attrib['name'] not in entries_without_duplicates:\n",
    "               entries_without_duplicates[obj.attrib['name']] = obj\n",
    "        entries_without_duplicates = [*entries_without_duplicates.values()]\n",
    "        #\n",
    "        for entry in entries_without_duplicates:\n",
    "            if entry.attrib['name'].lower() in sameroot_table[node1.key]:\n",
    "                sameroot_table[node1.key][str(entry.attrib['name']).lower()] = 1\n",
    "print(\"Прошло времени: \" + str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('большой', 'небольшой')\n",
      "[[46, 4], [11, 0], [149, 11]]\n",
      "('любимый', 'полюбить')\n",
      "[[5, 0], [54, 4]]\n",
      "('медведь', 'медвежонок')\n",
      "[[16, 1], [34, 3], [85, 7], [272, 20], [317, 22], [326, 23], [390, 26], [53, 4], [61, 5], [67, 6], [192, 15], [212, 16], [236, 18]]\n",
      "('подрезать', 'порезать')\n",
      "[[125, 9], [187, 14]]\n",
      "('расставаться', 'стать')\n",
      "[[26, 2], [43, 4], [366, 24]]\n"
     ]
    }
   ],
   "source": [
    "i, j = 0, 0\n",
    "sameroot_graph = dict()\n",
    "for col in sameroot_table:\n",
    "    j = 0\n",
    "    k = [col]\n",
    "    tmp = []\n",
    "    for row in sameroot_table[col]:\n",
    "        if j <= i: # slice top treugal matrix\n",
    "            j += 1\n",
    "            continue\n",
    "        if sameroot_table[col][row] == 1:\n",
    "            k.append(row)\n",
    "            for p in voc.get_node_by_key(col).pos:\n",
    "                tmp.append(p)\n",
    "            for p in voc.get_node_by_key(row).pos:\n",
    "                tmp.append(p)\n",
    "        j += 1\n",
    "    if len(k) > 1:\n",
    "        sameroot_graph[tuple(k)] = tmp\n",
    "    i += 1\n",
    "    \n",
    "for v in sameroot_graph:\n",
    "    print(v)\n",
    "    print(sameroot_graph[v])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "this is in <span style=\"color: #ff0000\">red</span> color."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1)В детстве у меня была любимая мягкая игрушка размером примерно с небольшую диванную подушку. (2)Это был медведь. (3)Я таскал его повсюду и даже в кроватке не расставался с ним. (4)Из всех игрушек ясельного возраста медведь был забыт самым последним. (5)В общем, я вырос, стал дядькой с большой бородой и татухами и вместо плюшевых медвежат полюбил мотоциклы. (6)И вот однажды мне приснился медвежонок из детства. (7)Сон был неприятный: медвежонок стоял в центре пустой комнаты, в мерцающем свете лампочки, а за окном как будто бы собирался ураган. (8)Медведь в упор смотрел на меня и тянул ко мне лапу, как будто показывал на что-то у меня за спиной, как будто предупреждал о чём-то. (9)Я не придал значения сну. (10)Однако на следующий день я ехал в мотоклуб, и девятка подрезала меня так, что я перелетел через руль и приземлился на живую изгородь, посаженную вдоль дороги. (11)Именно она меня и спасла. (12)Я получил ушибы, небольшой вывих плеча, а мотоцикл серьёзно пострадал и требовал дорогого ремонта. (13)Через неделю всё повторилось. (14)Всё в той же комнате при мерцающем свете и надвигающемся урагане. (15)Только сама игрушка выглядела грязной и потрёпанной, а в некоторых местах была порезана, и оттуда торчала вата. (16)Медвежонок по-прежнему настойчиво указывал на меня лапой. (17)Я решил съездить на дачу, которая была практически заброшена, и отыскать на чердаках-подвалах медвежонка среди барахла. (18)Перерыв там всё вверх дном, я в самом дальнем углу в пыльном мешке из-под картошки нашёл игрушку. (19)Сначала я достал голову медвежонка, оторванную с мясом, затем – тело с наполовину вылезшей через рваные дыры ватой. (20)Ещё час я потратил, чтобы найти в мелком мусоре на дне мешка пропавший шарик глаза, но так и не нашёл. (21)Я отвёз медведя домой и самолично его починил, хотя навыка такого у меня, конечно, не было. (22)Я постирал, набил его новой ватой, аккуратно зашил и даже слегка прошёлся утюгом, на место потерянного глаза я приделал чёрную повязку, как у пирата. (23)А позже с помощью знакомой из ателье медведь оделся в кожаную косуху с маленькими заклёпками. (24)Отныне медведь сидит у меня в гараже на самом видном месте, а иногда я устанавливаю его на вилку мотоцикла, и мы катаемся по городу или в мотоколоннах. (25)Соратники из клуба сначала смеялись, а потом привыкли, и игрушка даже в некотором роде стала нашим талисманом. (26)У меня давно была мечта – свой клуб для байкеров, и я его открою. (27)Я даже придумал ему название – Одноглазый медведь. "
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "colors = [\n",
    "    'on_grey',\n",
    "    'on_red',\n",
    "    'on_green',\n",
    "    'on_yellow',\n",
    "    'on_blue',\n",
    "    'on_magenta',\n",
    "    'on_cyan'\n",
    "]\n",
    "word_color = dict()\n",
    "i = 0\n",
    "for t in sameroot_graph.keys():\n",
    "    l = list(t)\n",
    "    for el in l:\n",
    "        word_color[el] = colors[i]\n",
    "    i += 1\n",
    "i = 0\n",
    "from IPython.display import Markdown\n",
    "display (Markdown('this is in <span style=\"color: #ff0000\">red</span> color.'))\n",
    "\n",
    "with open('D:\\\\Programms\\\\python programms\\\\diplom_lematizer_try1\\\\in.txt', 'rb') as file:\n",
    "    for line in file:\n",
    "        for word in line.decode(encoding='utf-8').split():\n",
    "            word_regex = re.sub('[.?!,:;%©*@#$^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}', '', word)\n",
    "            if word_regex in word_color:\n",
    "                print(colored(word, on_color=word_color[word_regex]), end=' ')\n",
    "            else:\n",
    "                print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# synset_relations для синонимов (ищется по senses)\n",
    "synsets_list = {\n",
    "    'A' : [*synsets_dict['A']], \n",
    "    'N' : [*synsets_dict['N']], \n",
    "    'V' : [*synsets_dict['V']]\n",
    "}\n",
    "synsets_table = dict()\n",
    "synsets_table['A'] = [[0 for x in range(len(synsets_list['A']))] for x in range(len(synsets_list['A']))] \n",
    "synsets_table['N'] = [[0 for x in range(len(synsets_list['N']))] for x in range(len(synsets_list['N']))] \n",
    "synsets_table['V'] = [[0 for x in range(len(synsets_list['V']))] for x in range(len(synsets_list['V']))] \n",
    "import time\n",
    "start = time.time()\n",
    "for pos in poses:\n",
    "    synset_relat = 'rwn\\\\synset_relations.' + pos + '.xml'\n",
    "    tree = etree.parse(synset_relat)\n",
    "    root = tree.getroot()\n",
    "    print(root)\n",
    "    for i in range(len(synsets_list[pos])):\n",
    "        for j in range(i, len(synsets_list[pos])):\n",
    "            entries = tree.xpath(\"//relation[@parent_id='\" + synsets_list[pos][i] + \"'][@child_id='\" + synsets_list[pos][j] + \"']\")\n",
    "            if len(entries) == 0:\n",
    "                continue\n",
    "            if synsets_dict[pos][synsets_list[pos][i]] == synsets_dict[pos][synsets_list[pos][j]]:\n",
    "                continue\n",
    "            synsets_table[pos][i][j] = 1\n",
    "print(\"Прошло времени: \" + str(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "A 53\n",
      "N 127\n",
      "V 153\n",
      "['БОЛЬШОЙ', 'ДАЛЬНИЙ']\n",
      "большой [[46, 4]] []\n",
      "дальний [[223, 17]] []\n",
      "\n",
      "['НОВЫЙ', 'ПОСЛЕДНИЙ']\n",
      "новый [[290, 21]] []\n",
      "последний [[38, 3]] []\n",
      "\n",
      "['ВОЗРАСТ', 'ДЕТСТВО']\n",
      "возраст [[33, 3]] []\n",
      "детство [[1, 0], [63, 5]] []\n",
      "\n",
      "['ГОЛОВА', 'РАЗМЕР']\n",
      "голова [[235, 18]] []\n",
      "размер [[8, 0]] []\n",
      "\n",
      "['ДЕНЬ', 'НЕДЕЛЯ']\n",
      "день [[118, 9], [260, 19]] []\n",
      "неделя [[161, 12]] []\n",
      "\n",
      "['ДНО', 'МЕСТО']\n",
      "дно [[219, 17]] []\n",
      "место [[185, 14], [300, 21], [335, 23]] []\n",
      "\n",
      "['ДЫРА', 'МЕСТО']\n",
      "дыра [[248, 18]] []\n",
      "место [[185, 14], [300, 21], [335, 23]] []\n",
      "\n",
      "['МЕДВЕДЬ', 'МЕДВЕЖОНОК']\n",
      "медведь [[16, 1], [34, 3], [85, 7], [272, 20], [317, 22], [326, 23], [390, 26]] []\n",
      "медвежонок [[53, 4], [61, 5], [67, 6], [192, 15], [212, 16], [236, 18]] []\n",
      "\n",
      "['МЕСТО', 'УГОЛ', 'ЦЕНТР']\n",
      "место [[185, 14], [300, 21], [335, 23]] []\n",
      "угол [[224, 17]] []\n",
      "центр [[70, 6]] []\n",
      "\n",
      "['ПЛЕЧО', 'ТЕЛО']\n",
      "плечо [[151, 11]] []\n",
      "тело [[242, 18]] []\n",
      "\n",
      "['СПИНА', 'ТЕЛО']\n",
      "спина [[104, 7]] []\n",
      "тело [[242, 18]] []\n",
      "\n",
      "['БЫТЬ', 'ВЫРАСТИ', 'СИДЕТЬ', 'СОБИРАТЬСЯ', 'СТОЯТЬ']\n",
      "быть [[4, 0], [15, 1], [35, 3], [65, 6], [186, 14], [205, 16], [285, 20], [372, 25]] []\n",
      "вырасти [[42, 4]] []\n",
      "сидеть [[327, 23]] []\n",
      "собираться [[83, 6]] []\n",
      "стоять [[68, 6]] []\n",
      "\n",
      "['БЫТЬ', 'ТОРЧАТЬ']\n",
      "быть [[4, 0], [15, 1], [35, 3], [65, 6], [186, 14], [205, 16], [285, 20], [372, 25]] []\n",
      "торчать [[190, 14]] []\n",
      "\n",
      "['БЫТЬ', 'ПОВТОРИТЬСЯ']\n",
      "быть [[4, 0], [15, 1], [35, 3], [65, 6], [186, 14], [205, 16], [285, 20], [372, 25]] []\n",
      "повториться [[163, 12]] []\n",
      "\n",
      "['ВЫГЛЯДЕТЬ', 'НАЙТИ']\n",
      "выглядеть [[178, 14]] []\n",
      "найти [[230, 17], [255, 19], [269, 19]] []\n",
      "\n",
      "['ДОСТАТЬ', 'ТАСКАТЬ']\n",
      "достать [[234, 18]] []\n",
      "таскать [[18, 2]] []\n",
      "\n",
      "['ДОСТАТЬ', 'ПОЛУЧИТЬ']\n",
      "достать [[234, 18]] []\n",
      "получить [[147, 11]] []\n",
      "\n",
      "['ДОСТАТЬ', 'ТОРЧАТЬ']\n",
      "достать [[234, 18]] []\n",
      "торчать [[190, 14]] []\n",
      "\n",
      "['ЕХАТЬ', 'КАТАТЬСЯ']\n",
      "ехать [[120, 9]] []\n",
      "кататься [[346, 23]] []\n",
      "\n",
      "['ЗАБРОСИТЬ', 'РАССТАВАТЬСЯ']\n",
      "забросить [[207, 16]] []\n",
      "расставаться [[26, 2]] []\n",
      "\n",
      "['НАБИТЬ', 'ПРИДЕЛАТЬ']\n",
      "набить [[288, 21]] []\n",
      "приделать [[304, 21]] []\n",
      "\n",
      "['ОТОРВАТЬ', 'РАССТАВАТЬСЯ']\n",
      "оторвать [[237, 18]] []\n",
      "расставаться [[26, 2]] []\n",
      "\n",
      "['ПОДРЕЗАТЬ', 'ПОРЕЗАТЬ']\n",
      "подрезать [[125, 9]] []\n",
      "порезать [[187, 14]] []\n",
      "\n",
      "['ПОКАЗЫВАТЬ', 'УКАЗЫВАТЬ']\n",
      "показывать [[98, 7]] []\n",
      "указывать [[195, 15]] []\n",
      "\n",
      "['ПОЛУЧИТЬ', 'ПОСТРАДАТЬ']\n",
      "получить [[147, 11]] []\n",
      "пострадать [[155, 11]] []\n",
      "\n",
      "['ПРИДЕЛАТЬ', 'СОБИРАТЬСЯ']\n",
      "приделать [[304, 21]] []\n",
      "собираться [[83, 6]] []\n",
      "\n",
      "['ПРИДУМАТЬ', 'РЕШИТЬ']\n",
      "придумать [[385, 26]] []\n",
      "решить [[200, 16]] []\n",
      "\n",
      "['РЕШИТЬ', 'СОБИРАТЬСЯ', 'УСТАНАВЛИВАТЬ']\n",
      "решить [[200, 16]] []\n",
      "собираться [[83, 6]] []\n",
      "устанавливать [[339, 23]] []\n",
      "\n",
      "['ТАСКАТЬ', 'ТЯНУТЬ']\n",
      "таскать [[18, 2]] []\n",
      "тянуть [[92, 7]] []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relation_nodes = []\n",
    "count = 0\n",
    "for pos in poses:\n",
    "    name_list = synsets_list[pos]\n",
    "    for i in range(len(synsets_list[pos])):\n",
    "        relations_i = []\n",
    "        synset_id_i = name_list[i]\n",
    "        word_i = synsets_dict[pos][synset_id_i]\n",
    "        for j in range(i, len(synsets_list[pos])):\n",
    "            if (synsets_table[pos][i][j] != 0):\n",
    "                synset_id_j = name_list[j]\n",
    "                word_j = synsets_dict[pos][synset_id_j]\n",
    "                if len(relations_i) == 0:\n",
    "                    relations_i.append(word_i[0])\n",
    "                if not word_j[0] in relations_i:\n",
    "                    relations_i.append(word_j[0])\n",
    "                count += 1\n",
    "        if len(relations_i) != 0:\n",
    "            relation_nodes.append(relations_i)\n",
    "print(count)\n",
    "print('A ' + str(len(synsets_list['A'])))\n",
    "print('N ' + str(len(synsets_list['N'])))\n",
    "print('V ' + str(len(synsets_list['V'])))\n",
    "for node in relation_nodes:\n",
    "    print(node)\n",
    "    for s in node:\n",
    "        node = voc.get_node_by_key(str(s).lower())\n",
    "        print(node.key, node.pos, node.dist)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
